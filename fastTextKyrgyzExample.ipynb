{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3Pvjw3ZlPnz",
        "outputId": "778d83b9-5ae5-4552-c2f5-f27519dd8396"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296184 sha256=789b3feec32d3b1930478b82c8690b0dfc00faf01a8c5d804fb861c1e758feed\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext.util\n",
        "# Жарым саат ~ бир саат жүктөйт\n",
        "fasttext.util.download_model('ky', if_exists='ignore')  # Kyrgyz\n",
        "model = fasttext.load_model('cc.ky.300.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53hj_OUwmaea",
        "outputId": "240560ee-66fd-4de3-d785-2f0cd4cb87f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ky.300.bin.gz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse = model.get_sentence_vector('Ат күчтүү жана ылдам.')"
      ],
      "metadata": {
        "id": "qKvAJUvwlPKX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = model.get_sentence_vector(\"Биздин топко жаңы адамдын атын кош.\")"
      ],
      "metadata": {
        "id": "bopvKVeVtvDQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity = cosine_similarity([horse], [name])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyZqLHpzuONk",
        "outputId": "7d5bdd7d-865a-436f-e75e-76e4820f6e62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.37710795]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse2 = model.get_sentence_vector(\"Ат тосмодон секирип өттү.\")\n",
        "\n",
        "similarity = cosine_similarity([horse], [horse2])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93v0q67Iuf7c",
        "outputId": "f29e126a-9c9c-4913-f5b0-32dcdf5f964c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.47417092]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name2 = model.get_sentence_vector(\"Клубдун атын ким ойлоп тапты?\")\n",
        "\n",
        "similarity = cosine_similarity([name], [name2])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF3ZNg-Nu9J3",
        "outputId": "1eff7011-74e4-4a05-e84f-745fde34d9af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5634349]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity([horse2], [name2])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjp0fht4vRtC",
        "outputId": "38ce2e75-aa23-4592-cfd1-8a68e69e0f32"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2855695]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse_sentences = [\n",
        "    \"Ат талаада чуркап баратат.\", \"Кечээ мен ат миндим.\", \"Атты сатып алгам.\",\n",
        "    \"Дыйкан атка жем берүүдө.\", \"Ат тосмодон секирип өттү.\", \"Аттар сулуу жаныбарлар.\",\n",
        "    \"Аттын жалынын кылдары бекем болот.\", \"Ат чөп жейт, бирок жемди көбүрөөк жакшы көрөт.\",\n",
        "    \"Балдар ат минип жүргөндү жакшы көрүшөт.\", \"Ат катуу кишенеди.\", \"Ал жаңы ат сатып алды.\",\n",
        "    \"Ат мөңкүп жатып, чабарманды ыргытып жиберди.\", \"Биз жапайы ат көрдүк.\", \"Кара ат жарышта жеңди.\",\n",
        "    \"Ат сарайда оонап жатат!\", \"Ал аттын жүнүн тарап койду.\", \"Ат арабаны тартып баратат.\", \"Алардын үч аты бар.\",\n",
        "    \"Ат күчтүү жана ылдам.\", \"Ат жана чабандес бирдей кыймылдады.\"\n",
        "]"
      ],
      "metadata": {
        "id": "tL-uxVjrvrTD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\"Чаптырып жүргөн атын уурдатып алыптыр\", \"Аты ала качып кетип, жыгылган экен\", \"Ашка ат союлду.\"]"
      ],
      "metadata": {
        "id": "YP0yFEqLxgAL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = [model.get_sentence_vector(sentence) for sentence in horse_sentences]"
      ],
      "metadata": {
        "id": "m4NL4q7zy1qT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "pairs = list(itertools.combinations(embeddings, 2))\n",
        "similarities = [cosine_similarity([pair[0]], [pair[1]])[0][0] for pair in pairs]\n",
        "# Calculate average similarity\n",
        "average_similarity = sum(similarities) / len(similarities)\n",
        "print(f\"Average Similarity Score: {average_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bqKr-tMz81h",
        "outputId": "3a7d1101-b018-45d4-fcc1-95c32eb38fd8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Similarity Score: 0.38370108668643393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shoot_sentences = [\"Сарбаз бутага так атты.\", \"Жаачы жебе атканга даярдады.\", \"Мергенчи бугуну атпай койду.\",\n",
        "\"Ал пистолетти колго алып, ат деп буйрук берди.\", \"Жоокерлер душманды көргөндө ата башташты.\",\n",
        "\"Күзөтчү абага атты.\", \"Мергенчи мылтык менен кушту атты.\", \"Ал бутага көздөй атты.\", \"Бала ойунчук куралдан суу атты.\",\n",
        "\"Башаламандыктарда бир нече жолу ок атылган.\", \"Жакын келбегиле, атам!\", \"Душмандарды коркутуу үчүн асманга ок атылды.\",\n",
        "\"Тынч эмес аймакта бир нече жолу атышуу болду.\", \"Күч органдары кылмышкерди атып салышкан.\", \"Ал ызы-чуу чыкканда абага ок атты.\",\n",
        "\"Полиция шектүүнү аткан жок.\", \"Совет бийлигинин буйругу менен атууга кеткет.\", \"Аскерлер буйрук күтүп, атпай турду.\", \"Кечке бутага аттык.\",\n",
        "\"Лагерге айдалып, андан ары атылып кеткен.\"]"
      ],
      "metadata": {
        "id": "Yyoz7HJ30LmF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = [model.get_sentence_vector(sentence) for sentence in shoot_sentences]"
      ],
      "metadata": {
        "id": "5a3xWelg1Bqj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "pairs = list(itertools.combinations(embeddings, 2))\n",
        "similarities = [cosine_similarity([pair[0]], [pair[1]])[0][0] for pair in pairs]\n",
        "# Calculate average similarity\n",
        "average_similarity = sum(similarities) / len(similarities)\n",
        "print(f\"Average Similarity Score: {average_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aN7VLrK1FCx",
        "outputId": "f004eb45-4677-4344-f48b-2287d712d38e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Similarity Score: 0.4510482430458069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shoot_sent = model.get_sentence_vector(shoot_sentences[5])\n",
        "horse_sent = model.get_sentence_vector(horse_sentences[7])\n",
        "sim = cosine_similarity([shoot_sent], [horse_sent])\n",
        "print(sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoSLSRvs1GiD",
        "outputId": "b4fe2ccf-9426-48b3-b17c-d1727852d5fd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.46285263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shoot_sentences[14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aOo7iP8T2qVl",
        "outputId": "a0e05565-9288-4faf-dab3-344d58fd64c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ал ызы-чуу чыкканда абага ок атты.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse_sentences[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VDax9i4T6XC3",
        "outputId": "a7030626-aecd-4f12-882c-1c3e7152c581"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Атты сатып алгам.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shoot_sent = model.get_sentence_vector(shoot_sentences[14])\n",
        "horse_sent = model.get_sentence_vector(horse_sentences[2])\n",
        "sim = cosine_similarity([shoot_sent], [horse_sent])\n",
        "print(sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN5iXVm-1O-X",
        "outputId": "69409360-316d-4673-bbbb-5c8e61b30b33"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.31485605]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We want to use a signal phrase that should check if it's closer to \"horses\" or \"shooting\""
      ],
      "metadata": {
        "id": "hh5j1ncr7G7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "signal_phrase_horse = \"жем берди\""
      ],
      "metadata": {
        "id": "TT416I-L6tXW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shoot_sent = model.get_sentence_vector(shoot_sentences[14])\n",
        "signal_phrase_horse_vec = model.get_sentence_vector(signal_phrase_horse)\n",
        "sim = cosine_similarity([shoot_sent], [signal_phrase_horse_vec])\n",
        "print(sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go3gJMVC61qN",
        "outputId": "9da355ec-d11a-42c2-d24c-0e233c3d3dad"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.25874266]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse_sent = model.get_sentence_vector(horse_sentences[2])\n",
        "sim = cosine_similarity([horse_sent], [signal_phrase_horse_vec])\n",
        "print(sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1qdrHFV44sr",
        "outputId": "679a899b-54f6-45ec-ff00-72c33f00a85d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.41549802]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use multiple signal phrases\n",
        "\n",
        "1. We have a dictionary of homonyms. Against every meaning there are 1) example sentences 2) multiple signal phrases: [\"чаптыруу\", \"ээр токун\", \"улак тартыш\"]\n",
        "2. Every time we get a sentence containing an ambigious word, we get its embeddings and compare against signal phrases of every meaning and see which one wins."
      ],
      "metadata": {
        "id": "cdu5w1mQ8Swo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambigious_words = {\n",
        "    \"ат\": {\n",
        "        \"name\": {\n",
        "            \"signal_phrases\": [\"ысым бер\", \"фамилия\", \"адам\"],\n",
        "        },\n",
        "        \"horse\": {\n",
        "            \"signal_phrases\": [\"чаптыруу\", \"ээр токун\", \"улак тартыш\"],\n",
        "        },\n",
        "        \"shoot\": {\n",
        "            \"signal_phrases\": [\"ок атуу\", \"мылтык\", \"автомат\", \"пистолет\", \"жаа\", \"аскер\", \"полиция\"],\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "5vt_Kb0t7gb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_avg_sim(sent_embedding, data):\n",
        "    signal_phrases = data.get('signal_phrases', [])\n",
        "    if not signal_phrases:\n",
        "        return 0  # Return zero if there are no signal phrases\n",
        "    sims = []\n",
        "    for phrase in signal_phrases:\n",
        "        phrase_embedding = model.get_sentence_vector(phrase)\n",
        "        sim = cosine_similarity([sent_embedding], [phrase_embedding])[0][0]\n",
        "        sims.append(sim)\n",
        "    avg_sim = sum(sims) / len(sims)\n",
        "    return avg_sim\n",
        "\n",
        "def disambiguator(word, sentence):\n",
        "    amb_word = ambigious_words.get(word)\n",
        "    if amb_word is None:\n",
        "        raise Exception(f\"Word '{word}' not found in our dictionary\")\n",
        "    results = []\n",
        "    sent_embedding = model.get_sentence_vector(sentence)\n",
        "    for meaning, data in amb_word.items():\n",
        "        avg_score = calculate_avg_sim(sent_embedding, data)\n",
        "        results.append((meaning, avg_score))\n",
        "    # Sort the results in descending order of average similarity\n",
        "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "    # Return the meaning with the highest average similarity score\n",
        "    return results[0][0]"
      ],
      "metadata": {
        "id": "ahDNMOBQFDsu"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlTZE7FBFFCY",
        "outputId": "be18d315-2bdc-4063-e36f-2631ece915bc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_labels',\n",
              " '_words',\n",
              " 'f',\n",
              " 'get_analogies',\n",
              " 'get_dimension',\n",
              " 'get_input_matrix',\n",
              " 'get_input_vector',\n",
              " 'get_label_id',\n",
              " 'get_labels',\n",
              " 'get_line',\n",
              " 'get_meter',\n",
              " 'get_nearest_neighbors',\n",
              " 'get_output_matrix',\n",
              " 'get_sentence_vector',\n",
              " 'get_subword_id',\n",
              " 'get_subwords',\n",
              " 'get_word_id',\n",
              " 'get_word_vector',\n",
              " 'get_words',\n",
              " 'is_quantized',\n",
              " 'labels',\n",
              " 'predict',\n",
              " 'quantize',\n",
              " 'save_model',\n",
              " 'set_args',\n",
              " 'set_matrices',\n",
              " 'test',\n",
              " 'test_label',\n",
              " 'words']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors(\"атты\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLb_4frDFcAO",
        "outputId": "55b8a5bf-261a-42bd-d2c3-becd2ec6d6a8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6032174825668335, 'аттыбы'),\n",
              " (0.5557559132575989, 'аттыш'),\n",
              " (0.5520542860031128, 'аттым'),\n",
              " (0.5266836285591125, 'аттыга'),\n",
              " (0.5206305980682373, 'аттыңыз'),\n",
              " (0.5135608315467834, 'чапчуу'),\n",
              " (0.501383364200592, 'аттың'),\n",
              " (0.47900187969207764, 'аттысы'),\n",
              " (0.4695969521999359, 'аттык'),\n",
              " (0.4694654941558838, 'аттырбай')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_exeoxpFg8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}