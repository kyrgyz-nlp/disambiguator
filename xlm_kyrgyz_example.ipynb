{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "701271ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf181b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM-ROBERTA-BASE\n",
    "model_xlm_roberta_base_name = 'xlm-roberta-base'\n",
    "tokenizer_xlm_roberta_base = AutoTokenizer.from_pretrained(model_xlm_roberta_base_name)\n",
    "model_xlm_roberta_base = AutoModel.from_pretrained(model_xlm_roberta_base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b553cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text, tokenizer, model=model_xlm_roberta_base):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    # Get the hidden states (embeddings) from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Average the token embeddings (to get a single vector for the sentence)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfd0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_similarity(embed1, embed2):\n",
    "    embedding1_np = embed1.numpy()\n",
    "    embedding2_np = embed2.numpy()\n",
    "\n",
    "    # Compute the cosine similarity between the two embeddings\n",
    "    similarity_score = cosine_similarity(embedding1_np, embedding2_np)\n",
    "#     print(f\"Cosine similarity between the texts: {similarity_score[0][0]:.4f}\")\n",
    "    return similarity_score[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181e9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(text1, text2, tokenizer=tokenizer_xlm_roberta_base, model=model_xlm_roberta_base):\n",
    "    embedding1 = get_text_embedding(text1, tokenizer, model)\n",
    "    embedding2 = get_text_embedding(text2, tokenizer, model)\n",
    "    cos_sim = get_cos_similarity(embedding1, embedding2)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f8577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf558af",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_1 = 'Ат күчтүү жана ылдам.'\n",
    "name_1 = \"Биздин топко жаңы адамдын атын кош.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29eb58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = get_text_embedding(horse_1, tokenizer_xlm_roberta_base, model_xlm_roberta_base)\n",
    "emb2 = get_text_embedding(name_1, tokenizer_xlm_roberta_base, model_xlm_roberta_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c784a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99657124]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22875ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99657124"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cos_similarity(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa5f632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99657124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cos_sim(horse_1, name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a9dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_2 = \"Ат тосмодон секирип өттү.\"\n",
    "name_2 = \"Клубдун атын ким ойлоп тапты?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b77a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99574625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cos_sim(horse_2, name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e16a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbb8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_sentences = [\n",
    "    \"Ат талаада чуркап баратат.\", \"Кечээ мен ат миндим.\", \"Атты сатып алгам.\",\n",
    "    \"Дыйкан атка жем берүүдө.\", \"Ат тосмодон секирип өттү.\", \"Аттар сулуу жаныбарлар.\",\n",
    "    \"Аттын жалынын кылдары бекем болот.\", \"Ат чөп жейт, бирок жемди көбүрөөк жакшы көрөт.\",\n",
    "    \"Балдар ат минип жүргөндү жакшы көрүшөт.\", \"Ат катуу кишенеди.\", \"Ал жаңы ат сатып алды.\",\n",
    "    \"Ат мөңкүп жатып, чабарманды ыргытып жиберди.\", \"Биз жапайы ат көрдүк.\", \"Кара ат жарышта жеңди.\",\n",
    "    \"Ат сарайда оонап жатат!\", \"Ал аттын жүнүн тарап койду.\", \"Ат арабаны тартып баратат.\", \"Алардын үч аты бар.\",\n",
    "    \"Ат күчтүү жана ылдам.\", \"Ат жана чабандес бирдей кыймылдады.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0443e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\"Чаптырып жүргөн атын уурдатып алыптыр\", \"Аты ала качып кетип, жыгылган экен\", \"Ашка ат союлду.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a692b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c86237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Horse': Average Similarity Score: 0.9925870528346614\n"
     ]
    }
   ],
   "source": [
    "pairs_horse = list(itertools.combinations(horse_sentences, 2))\n",
    "similarities_horse = [get_cos_sim([pair[0]], [pair[1]]) for pair in pairs_horse]\n",
    "# Calculate average similarity\n",
    "average_similarity_horse = sum(similarities_horse) / len(similarities_horse)\n",
    "print(f\"'Horse': Average Similarity Score: {average_similarity_horse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca321c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a92ac164",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoot_sentences = [\"Сарбаз бутага так атты.\", \"Жаачы жебе атканга даярдады.\", \"Мергенчи бугуну атпай койду.\",\n",
    "\"Ал пистолетти колго алып, ат деп буйрук берди.\", \"Жоокерлер душманды көргөндө ата башташты.\",\n",
    "\"Күзөтчү абага атты.\", \"Мергенчи мылтык менен кушту атты.\", \"Ал бутага көздөй атты.\", \"Бала ойунчук куралдан суу атты.\",\n",
    "\"Башаламандыктарда бир нече жолу ок атылган.\", \"Жакын келбегиле, атам!\", \"Душмандарды коркутуу үчүн асманга ок атылды.\",\n",
    "\"Тынч эмес аймакта бир нече жолу атышуу болду.\", \"Күч органдары кылмышкерди атып салышкан.\", \"Ал ызы-чуу чыкканда абага ок атты.\",\n",
    "\"Полиция шектүүнү аткан жок.\", \"Совет бийлигинин буйругу менен атууга кеткет.\", \"Аскерлер буйрук күтүп, атпай турду.\", \"Кечке бутага аттык.\",\n",
    "\"Лагерге айдалып, андан ары атылып кеткен.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e721a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Shoot': Average Similarity Score: 0.9943701612321953\n"
     ]
    }
   ],
   "source": [
    "pairs_shoot = list(itertools.combinations(shoot_sentences, 2))\n",
    "similarities_shoot = [get_cos_sim([pair[0]], [pair[1]]) for pair in pairs_shoot]\n",
    "# Calculate average similarity\n",
    "average_similarity_shoot = sum(similarities_shoot) / len(similarities_shoot)\n",
    "print(f\"'Shoot': Average Similarity Score: {average_similarity_shoot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbab8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5360429f",
   "metadata": {},
   "source": [
    "Here we see that the avg cosine similarity is quite high for sentences close meaningfully for both categories: \"Horse\" and \"Shoot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa11898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd89bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Horse-Shoot': Average Similarity Score: 0.9927406707406043\n"
     ]
    }
   ],
   "source": [
    "pairs_horse_shoot = list(itertools.product(horse_sentences, shoot_sentences))\n",
    "similarities_horse_shoot = [get_cos_sim([pair[0]], [pair[1]]) for pair in pairs_horse_shoot]\n",
    "# Calculate average similarity\n",
    "average_similarity_horse_shoot = sum(similarities_horse_shoot) / len(similarities_horse_shoot)\n",
    "print(f\"'Horse-Shoot': Average Similarity Score: {average_similarity_horse_shoot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f01db7",
   "metadata": {},
   "source": [
    "Also we see thath the avg similarity between sentences from different categories is pretty high. It's unexpectedly wierd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7784075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd88916a",
   "metadata": {},
   "source": [
    "## Use multiple signal phrases\n",
    "\n",
    "1. We have a dictionary of homonyms. Against every meaning there are 1) example sentences 2) multiple signal phrases: [\"чаптыруу\", \"ээр токун\", \"улак тартыш\"]\n",
    "2. Every time we get a sentence containing an ambigious word, we get its embeddings and compare against signal phrases of every meaning and see which one wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97adfede",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambigious_words = {\n",
    "    \"ат\": {\n",
    "        \"name\": {\n",
    "            \"signal_phrases\": [\"ысым бер\", \"фамилия\", \"адам\"],\n",
    "        },\n",
    "        \"horse\": {\n",
    "            \"signal_phrases\": [\"чаптыруу\", \"ээр токун\", \"улак тартыш\"],\n",
    "        },\n",
    "        \"shoot\": {\n",
    "            \"signal_phrases\": [\"ок атуу\", \"мылтык\", \"автомат\", \"пистолет\", \"жаа\", \"аскер\", \"полиция\"],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6490201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_sim(sent_text, data):\n",
    "    signal_phrases = data.get('signal_phrases', [])\n",
    "    if not signal_phrases:\n",
    "        return 0  # Return zero if there are no signal phrases\n",
    "    sims = []\n",
    "    for phrase in signal_phrases:\n",
    "#         phrase_embedding = model.get_sentence_vector(phrase)\n",
    "#         sim = cosine_similarity([sent_embedding], [phrase_embedding])[0][0]\n",
    "        sim = get_cos_sim(sent_text, phrase)\n",
    "        sims.append(sim)\n",
    "    avg_sim = sum(sims) / len(sims)\n",
    "    return avg_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6389318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguator(word, sentence):\n",
    "    amb_word = ambigious_words.get(word)\n",
    "    if amb_word is None:\n",
    "        raise Exception(f\"Word '{word}' not found in our dictionary\")\n",
    "    results = []\n",
    "#     sent_embedding = model.get_sentence_vector(sentence)\n",
    "    for meaning, data in amb_word.items():\n",
    "        avg_score = calculate_avg_sim(sentence, data)\n",
    "        results.append((meaning, avg_score))\n",
    "    # Sort the results in descending order of average similarity\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    # Return the meaning with the highest average similarity score\n",
    "    return results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68a1f149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_avg_sim(horse_sentences[0], ambigious_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eff3397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Horse\" accuracy = 0.95\n"
     ]
    }
   ],
   "source": [
    "n_horse = len(horse_sentences)\n",
    "correct_horse = 0\n",
    "\n",
    "for horse_sent in horse_sentences:\n",
    "    answer = disambiguator('ат', horse_sent)\n",
    "#     print(answer)\n",
    "    if answer == 'horse':\n",
    "        correct_horse += 1\n",
    "print(f'\"Horse\" accuracy = {correct_horse / n_horse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd13aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Shoot\" accuracy = 0.0\n"
     ]
    }
   ],
   "source": [
    "n_shoot = len(shoot_sentences)\n",
    "correct_shoot = 0\n",
    "\n",
    "for shoot_sent in shoot_sentences:\n",
    "    answer = disambiguator('ат', shoot_sent)\n",
    "#     print(answer)\n",
    "    if answer == 'shoot':\n",
    "        correct_shoot += 1\n",
    "print(f'\"Shoot\" accuracy = {correct_shoot / n_shoot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a8144f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391e0e67",
   "metadata": {},
   "source": [
    "Load our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45128cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"sentences.json\"\n",
    "\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee0768b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_ambiguous_words_50 = \"ambiguous_words_50.json\"\n",
    "\n",
    "with open(json_file_ambiguous_words_50, 'r', encoding='utf-8') as f:\n",
    "    ambiguous_words_50 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c8b6b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ач', 'же', 'ак', 'кап', 'ала', 'кеч', 'кош', 'кал', 'бай', 'сай', 'арык', 'кой', 'ай', 'топ', 'жар', 'тил', 'каз', 'там', 'жаш', 'кара', 'мал', 'сөз', 'бас', 'тек', 'уч', 'жең', 'курак', 'айт', 'түш', 'кур', 'тай', 'кол', 'күн', 'ат', 'жаз', 'кат', 'сан', 'чал', 'кир', 'чек', 'бак', 'аябай', 'ачуу'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86f0abb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ач', 'же', 'ак', 'кап', 'ала', 'кеч', 'кош', 'кал', 'бай', 'сай', 'арык', 'кой', 'ай', 'топ', 'жар', 'тил', 'каз', 'там', 'жаш', 'кара', 'мал', 'сөз', 'бас', 'тек', 'уч', 'жең', 'курак', 'айт', 'түш', 'кур', 'тай', 'кол', 'күн', 'ат', 'жаз', 'кат', 'сан', 'чал', 'кир', 'чек', 'бак', 'аябай', 'ачуу'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous_words_50.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d64fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sentences.keys()) == set(ambiguous_words_50.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dee300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afe989fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'open': {'signal_phrases': ['ачуу',\n",
       "   'эшикти ачуу',\n",
       "   'жарык',\n",
       "   'кирүү',\n",
       "   'жолду ач',\n",
       "   'ачылыш',\n",
       "   'ачылышы',\n",
       "   'ачык']},\n",
       " 'hungry': {'signal_phrases': ['ач карын',\n",
       "   'тамакка муктаж',\n",
       "   'ачтык',\n",
       "   'курсак ачуу',\n",
       "   'ачка болуу']}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambigious_words['ач']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d88a6637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "containers of amb_word 'там' in json mismatch! This key is deleted.\n"
     ]
    }
   ],
   "source": [
    "# Merge JSONs\n",
    "ambigious_words = ambiguous_words_50.copy()\n",
    "for amb_word, meanings in ambiguous_words_50.items():\n",
    "    if set(meanings.keys()) != set(sentences[amb_word].keys()):\n",
    "        print(f\"containers of amb_word '{amb_word}' in json mismatch! This key is deleted.\")\n",
    "        del ambigious_words[amb_word]\n",
    "        continue\n",
    "    for meaning in meanings.keys():\n",
    "        ambigious_words[amb_word][meaning][\"sentences\"] = sentences[amb_word][meaning][\"sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0247e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to json\n",
    "with open('ambigious_words.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(ambigious_words, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47f3be48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'open': {'signal_phrases': ['ачуу',\n",
       "   'эшикти ачуу',\n",
       "   'жарык',\n",
       "   'кирүү',\n",
       "   'жолду ач',\n",
       "   'ачылыш',\n",
       "   'ачылышы',\n",
       "   'ачык'],\n",
       "  'sentences': ['Ач дегенде ача кал да!']},\n",
       " 'hungry': {'signal_phrases': ['ач карын',\n",
       "   'тамакка муктаж',\n",
       "   'ачтык',\n",
       "   'курсак ачуу',\n",
       "   'ачка болуу'],\n",
       "  'sentences': ['Ач көздүгүнөн ушундай абалга келип отурбайбы']}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "ambigious_words['ач']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbc6985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hungry\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "answer = disambiguator('ач', \"Ач дегенде ача кал да!\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ff995ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 42: amb_word = ач\n",
      "2 / 42: amb_word = же\n",
      "4 / 42: amb_word = ак\n",
      "6 / 42: amb_word = кап\n",
      "9 / 42: amb_word = ала\n",
      "12 / 42: amb_word = кеч\n",
      "14 / 42: amb_word = кош\n",
      "16 / 42: amb_word = кал\n",
      "18 / 42: amb_word = бай\n",
      "20 / 42: amb_word = сай\n",
      "22 / 42: amb_word = арык\n",
      "24 / 42: amb_word = кой\n",
      "26 / 42: amb_word = ай\n",
      "29 / 42: amb_word = топ\n",
      "31 / 42: amb_word = жар\n",
      "34 / 42: amb_word = тил\n",
      "47 / 42: amb_word = каз\n",
      "49 / 42: amb_word = жаш\n",
      "52 / 42: amb_word = кара\n",
      "54 / 42: amb_word = мал\n",
      "56 / 42: amb_word = сөз\n",
      "58 / 42: amb_word = бас\n",
      "60 / 42: amb_word = тек\n",
      "62 / 42: amb_word = уч\n",
      "64 / 42: amb_word = жең\n",
      "66 / 42: amb_word = курак\n",
      "68 / 42: amb_word = айт\n",
      "70 / 42: amb_word = түш\n",
      "73 / 42: amb_word = кур\n",
      "76 / 42: amb_word = тай\n",
      "84 / 42: amb_word = кол\n",
      "86 / 42: amb_word = күн\n",
      "88 / 42: amb_word = ат\n",
      "91 / 42: amb_word = жаз\n",
      "95 / 42: amb_word = кат\n",
      "108 / 42: amb_word = сан\n",
      "110 / 42: amb_word = чал\n",
      "114 / 42: amb_word = кир\n",
      "117 / 42: amb_word = чек\n",
      "119 / 42: amb_word = бак\n",
      "121 / 42: amb_word = аябай\n",
      "123 / 42: amb_word = ачуу\n",
      "CPU times: total: 31min 18s\n",
      "Wall time: 8min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "count_correct = 0\n",
    "count_all = 0\n",
    "n = len(ambigious_words.keys())\n",
    "for amb_word, meanings in ambigious_words.items():\n",
    "    print(f\"{count_all} / {n}: amb_word = {amb_word}\")\n",
    "    for meaning, val in meanings.items():\n",
    "        for sent in val[\"sentences\"]:\n",
    "            answer = disambiguator(amb_word, sent)\n",
    "            count_all += 1\n",
    "            if answer == meaning:\n",
    "                count_correct += 1\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7f4c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.368\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy = {count_correct / count_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5889bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
